---
title: Probability
author: Yourui Wang
date: 2025-10-14
category: Jekyll
layout: post
---
## Knowlege 1. Important Distributions

### Knowlege 1 (Geometric Distribution)

If $X$ conforms to **geometric distribution** with parameter $p$, then $X$ counts the number of trials unitl the first sucess in a sequence of independent Bernoulli trials with probability $p$, the probability distribution of $X$ is
$$
\mathbb{P}(X=n)=(1-p)^{n-1}p,\quad n=1, 2, \cdots
$$

Then $X$ has the property that

$$
\mathbb{E}(X)=\frac{1}{p}, \text{Var}(X)=\frac{1-p}{p^2}
$$

An intuitive way to understand the expectation of $X$ is,

* Each trial succeeds with prob $p$
* On average, among $n$ trials you expect $np$ successes
* To get 1 success, you need $n=1/p$ trials on average

## Knowlege 2. Important Calculus

### Knowlege 2-1


$$
\int_{-\infty}^{+\infty}e^{-x^2}dx=\sqrt{\pi}
$$

**Comment**

* Notice that this is exactly $\Gamma(1/2)$ in [**Knowlege 2-3 (Gamma Function)**](#knowlege-2-3-gamma-function)
* Related to the probability density function of normal distribution

### **Knowlege 2-2 (Beta Function)**

Beta function $B(x,y)$ is defined as


$$
B(x,y)=\int_0^1t^{x-1}(1-t)^{y-1}dt
$$


where $x>0$ and $y > 0$. It has the properties like


$$
B(x,y)=B(y,x)
$$

$$
B(x,y+1)=\frac{y}{x+y}B(x,y)
$$

### **Knowlege 2-3 (Gamma Function)**

Gamma function $\Gamma(z)$ is defined as


$$
\Gamma(z)=\int_0^\infty t^{z-1}e^{-t}dt
$$


where $z>0$. It has properties like


$$
\Gamma(z+1)=z\Gamma(z),\quad \Gamma(n)=(n-1)!\text{ if }n\in\mathbb{N}^+
$$

$$
\Gamma(z)\Gamma(1-z)=\frac{\pi}{\sin(\pi z)}\text{ where }x\notin\mathbb{N},\quad \Gamma(\frac{1}{2})=\sqrt{\pi}
$$

$$
B(x,y)=\frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}
$$

**Comment**

* Notice that $\Gamma(\frac{1}{2})=\sqrt{\pi}$ is exactly $\int_{-\infty}^{+\infty}e^{-x^2}dx$ in [**Knowlege 2-1**](#knowlege-2-1)















